{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "miniproject_class_release_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOcdR9GoQ3t2zB2I02PpIbq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5fe85803eb984b0f8a1edfd90e4c9c70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_42aa91904f3b470784f0839ef39a0725",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4507d95a21aa44b18d059521579b0361",
              "IPY_MODEL_ad502b0d15ed4911bf74d736e12f0db4"
            ]
          }
        },
        "42aa91904f3b470784f0839ef39a0725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4507d95a21aa44b18d059521579b0361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_39ca522efb094fabb088490c640b950b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d7aac5b12b994160897adc9bf0288fb1"
          }
        },
        "ad502b0d15ed4911bf74d736e12f0db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_08f0e932b24a4e119c97964b211937e7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:01&lt;00:00, 80.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_19ba5916680b4c3792036a98ccd659ed"
          }
        },
        "39ca522efb094fabb088490c640b950b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d7aac5b12b994160897adc9bf0288fb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08f0e932b24a4e119c97964b211937e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "19ba5916680b4c3792036a98ccd659ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iob9NrP0ELLj"
      },
      "source": [
        "#Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmywhJKvJKkJ"
      },
      "source": [
        "#Melanoma\n",
        "| metrics     | implementation | Original |\n",
        "|-------------|-------------------|----------|\n",
        "| AUC         | 0.852             | 0.875    |\n",
        "| Accuracy    | 0.852             | 0.850    |\n",
        "| Specificity | 0.952             | 0.896     |\n",
        "| Sensitivity | 0.436             | 0.658    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9RpoQwt19NH"
      },
      "source": [
        "#Seborrheic Keratosis\n",
        "\n",
        "| metrics     | implementation | Original |\n",
        "|-------------|-------------------|----------|\n",
        "| AUC         | 0.940             | 0.958    |\n",
        "| Accuracy    | 0.921             | 0.868    |\n",
        "| Specificity | 0.966             | 0.867    |\n",
        "| Sensitivity | 0.666             | 0.878    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMzwz8HA3g_5"
      },
      "source": [
        "#Average\n",
        "| metrics | implementation | Original |\n",
        "|---------|----------------|----------|\n",
        "| AUC     | 0.896          | 0.917    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_ANl0fZJy0k"
      },
      "source": [
        "#Train_Mel.py is the training code\n",
        "#predict2017.py is the test code\n",
        "  ### make sure to run the previous cells before you run train_mel.py or predict2017.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ofcdDdlI8gJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5d1f836-2a6b-4623-c533-461cf2d0c445"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_wBKX0CJO7M"
      },
      "source": [
        "base_path = '/content/gdrive/My Drive/ISIC-2017-Org-Train-Data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW7UXmDiSu1k"
      },
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Hh1CnAyrR-Ph"
      },
      "source": [
        "#@title generate_patch_images.py { form-width: \"50px\" }\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import glob as gb\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "def get_images(root_path):\n",
        "    files = []\n",
        "    for ext in ['jpg']:\n",
        "        files.extend(gb.glob(os.path.join(root_path, '*.{}'.format(ext))))\n",
        "    return files\n",
        "\n",
        "def rescale_crop(image, scale, num, ori=False):\n",
        "    image_list = []\n",
        "    h, w = image.size\n",
        "    if ori:\n",
        "        trans = transforms.Resize((224,224))\n",
        "    else:\n",
        "        trans = transforms.Compose([\n",
        "        transforms.CenterCrop((int(h * scale) + 350 * scale, int(w * scale) + 350 * scale)),\n",
        "        transforms.RandomCrop((int(h * scale), int(w * scale))),\n",
        "        transforms.Resize((224,224))\n",
        "    ])\n",
        "    for i in range(num):\n",
        "        img = trans(image)\n",
        "        image_list.append(img)\n",
        "    return image_list\n",
        "\n",
        "data_dir = \"/content/gdrive/My Drive/ISIC-2017-Org-Train-Data/After-Segmentation-4/\"\n",
        "new_data_dir = base_path +'ISIC-2017_Training_Data_Patch_Final/'\n",
        "excel_dir = base_path + \"ISIC-2017_Training_Part3_GroundTruth.csv\"\n",
        "new_excel_dir = base_path + \"ISIC-2017_Training_Part3_GroundTruth_patch_final.csv\"\n",
        "images = get_images(data_dir)\n",
        "\n",
        "if not os.path.exists(new_data_dir):\n",
        "    os.makedirs(new_data_dir)\n",
        "\n",
        "\n",
        "ids = []\n",
        "mels = []\n",
        "sks = []\n",
        "for img in tqdm(images):\n",
        "    image = Image.open(img)\n",
        "    labels = pd.read_csv(excel_dir)\n",
        "    mel = int(labels.loc[labels['image_id'] == img[img.rfind('/')+1:-4]]['melanoma'].values.squeeze())\n",
        "    sk = int(labels.loc[labels['image_id'] == img[img.rfind('/')+1:-4]]['seborrheic_keratosis'].values.squeeze())\n",
        "    image_list1 = rescale_crop(image, 0.2, 15)\n",
        "    image_list2 = rescale_crop(image, 0.4, 15)\n",
        "    image_list3 = rescale_crop(image, 0.6, 15)\n",
        "    image_list4 = rescale_crop(image, 0.8, 15)\n",
        "    image_list5 = rescale_crop(image, 1, 1, True)\n",
        "    image_list_all = image_list1 + image_list2 + image_list3 + image_list4 + image_list5\n",
        "\n",
        "    for i in range(len(image_list_all)):\n",
        "        new_name = img[img.rfind('/')+1:-4] + '_' + str(i) + '.png'\n",
        "        new_dir = os.path.join(new_data_dir, new_name)\n",
        "        image_list_all[i].save(new_dir)\n",
        "        labels = pd.read_csv(excel_dir)\n",
        "        ids.append(new_name[:-4])\n",
        "        mels.append(mel)\n",
        "        sks.append(sk)\n",
        "data_frame = pd.DataFrame({\"image_id\": ids, \"melanoma\": mels, \"seborrheic_keratosis\": sks})\n",
        "data_frame.to_csv(new_excel_dir, index=False, sep=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrYdrHkxJUFg"
      },
      "source": [
        "#@title dataset2017.py || prepares and preprocesses the data for training,validatation and testing { form-width: \"50px\" }\n",
        "from torch.utils import data\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "class ISICDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, path, mode=\"training\", crop=None, transform=None, task=None):\n",
        "        self.path = path\n",
        "        self.mode = mode\n",
        "        self.samples = self.make_dataset(path)\n",
        "        self.crop = crop\n",
        "        self.transform = transform\n",
        "        self.task = task\n",
        "        self.image_list = []\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, melanoma, seborrheic_keratosis = self.samples[idx]\n",
        "        img_name = img_path.split(\"/\")[-1]\n",
        "        image = self.pil_loader(img_path)\n",
        "        if self.crop:\n",
        "            image = self.crop(image)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.task==\"mel\":\n",
        "            return image, torch.from_numpy(np.array(int(melanoma))), img_name\n",
        "        elif self.task==\"sk\":\n",
        "            return image, torch.from_numpy(np.array(int(seborrheic_keratosis))), img_name\n",
        "        else:\n",
        "            return image, torch.FloatTensor([torch.from_numpy(np.array(int(melanoma))), torch.from_numpy(np.array(int(seborrheic_keratosis)))]), img_name\n",
        "        \n",
        "\n",
        "    def pil_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "    def make_dataset(self, dir):\n",
        "        images = []\n",
        "        if self.mode == \"training\":\n",
        "            img_dir = os.path.join(dir, \"ISIC-2017_Training_Data_Patch_Final\")\n",
        "            csv_filename = os.path.join(dir, \"ISIC-2017_Training_Part3_GroundTruth_patch_final.csv\")\n",
        "        if self.mode == \"validation\":\n",
        "            img_dir = os.path.join(dir, \"After-Enhancement-Val-2\")\n",
        "            csv_filename = os.path.join(dir, \"validation_gt.csv\")\n",
        "        if self.mode == \"testing\":\n",
        "            img_dir = os.path.join(dir, \"ISIC-2017_Test_v2_Data\")\n",
        "            csv_filename = os.path.join(dir, \"ISIC-2017_Test_v2_Part3_GroundTruth.csv\")\n",
        "        label_list = pd.read_csv(csv_filename)\n",
        "\n",
        "        for index, row in label_list.iterrows():\n",
        "            if self.mode == \"training\":\n",
        "                images.append((os.path.join(img_dir, row[\"image_id\"] + \".png\"), row[\"melanoma\"], row[\"seborrheic_keratosis\"]))\n",
        "            else:\n",
        "                images.append((os.path.join(img_dir, row[\"image_id\"] + \".jpg\"), row[\"melanoma\"], row[\"seborrheic_keratosis\"]))\n",
        "        return images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6No2_3LUJZta"
      },
      "source": [
        "#@title crop_transform.py || applies required transforms on the image{ form-width: \"50px\" }\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob as gb\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import warnings\n",
        "from scipy import ndimage\n",
        "import cv2\n",
        "def rescale_crop(image, scale, num, mode):\n",
        "    image_list = []\n",
        "    h, w = image.size\n",
        "    if mode==\"train\":\n",
        "        trans = transforms.Compose([\n",
        "        transforms.CenterCrop((int(h * scale) + 500 * scale, int(w * scale) + 500 * scale)),\n",
        "        transforms.RandomCrop((int(h * scale), int(w * scale))),\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.RandomRotation((-10,10)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "    ])\n",
        "    elif mode==\"val\":\n",
        "        trans = transforms.Compose([\n",
        "            transforms.CenterCrop((int(h * scale) + 500 * scale, int(w * scale) + 500 * scale)),\n",
        "            transforms.RandomCrop((int(h * scale), int(w * scale))),\n",
        "            transforms.Resize((224, 224)),\n",
        "        ])\n",
        "    for i in range(num):\n",
        "        img = trans(image)\n",
        "        image_list.append(img)\n",
        "    return image_list\n",
        "\n",
        "def crop(image, mode):\n",
        "    image_list = []\n",
        "    if mode==\"train\":\n",
        "        trans = transforms.Compose([\n",
        "\n",
        "        transforms.RandomRotation((-10, 10)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.Resize((224, 224)),  #change the order\n",
        "    ])\n",
        "    elif mode==\"val\":\n",
        "        trans = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "        ])\n",
        "    img = trans(image)\n",
        "    image_list.append(img)\n",
        "    return image_list\n",
        "\n",
        "class argumentation(object):\n",
        "    def __call__(self, image):\n",
        "        image_list1 = rescale_crop(image, 0.2, 15, \"train\")\n",
        "        image_list2 = rescale_crop(image, 0.4, 15, \"train\")\n",
        "        image_list3 = rescale_crop(image, 0.6, 15, \"train\")\n",
        "        image_list4 = rescale_crop(image, 0.8, 15, \"train\")\n",
        "        image_list5 = crop(image, \"train\")\n",
        "        image_list = image_list1 + image_list2 + image_list3 + image_list4 + image_list5\n",
        "        nomalize = transforms.Lambda(lambda crops: torch.stack([transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.7079057, 0.59156483, 0.54687315],\n",
        "                             std=[0.09372108, 0.11136277, 0.12577087])])(crop) for crop in crops]))\n",
        "        random.shuffle(image_list)\n",
        "        image_list = nomalize(image_list)\n",
        "        return image_list\n",
        "\n",
        "class argumentation_val(object):\n",
        "    def __call__(self, image):\n",
        "        image_list1 = rescale_crop(image, 0.2, 2, \"val\")\n",
        "        image_list2 = rescale_crop(image, 0.4, 2, \"val\")\n",
        "        image_list3 = rescale_crop(image, 0.6, 2, \"val\")\n",
        "        image_list4 = rescale_crop(image, 0.8, 2, \"val\")\n",
        "        image_list5 = crop(image, \"val\")\n",
        "        image_list = image_list1 + image_list2 + image_list3 + image_list4 + image_list5\n",
        "        nomalize = transforms.Lambda(lambda crops: torch.stack([transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.7079057, 0.59156483, 0.54687315],\n",
        "                             std=[0.09372108, 0.11136277, 0.12577087])])(crop) for crop in crops]))\n",
        "        image_list = nomalize(image_list)\n",
        "        return image_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6uJo-5FJcl7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "5fe85803eb984b0f8a1edfd90e4c9c70",
            "42aa91904f3b470784f0839ef39a0725",
            "4507d95a21aa44b18d059521579b0361",
            "ad502b0d15ed4911bf74d736e12f0db4",
            "39ca522efb094fabb088490c640b950b",
            "d7aac5b12b994160897adc9bf0288fb1",
            "08f0e932b24a4e119c97964b211937e7",
            "19ba5916680b4c3792036a98ccd659ed"
          ]
        },
        "cellView": "form",
        "outputId": "0bfec8e9-76d4-40e9-acf6-eac7e2146ebb"
      },
      "source": [
        "#@title ARL.py || code for ARL Model {form-width:\"50px\"}\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "import torch.nn.init\n",
        "\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "}\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, alpha =0.001):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        attention = nn.Softmax2d(out)\n",
        "\n",
        "        out = out + residual + self.alpha * attention * residual\n",
        "\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, alpha = 0.001):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        attention = nn.Softmax2d()(out)\n",
        "\n",
        "        out = out + residual + self.alpha * attention *residual\n",
        "\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ARLNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1):\n",
        "        self.inplanes = 64\n",
        "        super(ARLNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])    #3\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2) #4\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)  #6\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)  #3\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc_ = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def arlnet18(pretrained=False, **kwargs):\n",
        "    model = ARLNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
        "    if pretrained:\n",
        "        model_pretrained = model_zoo.load_url(model_urls['resnet18'])\n",
        "        model_dict = model.state_dict()\n",
        "        pretrained_dict = {k: v for k, v in model_pretrained.items() if k in model_dict}\n",
        "        model_dict.update(pretrained_dict)\n",
        "        model.load_state_dict(model_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def arlnet34(pretrained=False, **kwargs):\n",
        "    \n",
        "    model = ARLNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model_pretrained = model_zoo.load_url(model_urls['resnet34'])\n",
        "        model_dict = model.state_dict()\n",
        "        pretrained_dict = {k: v for k, v in model_pretrained.items() if k in model_dict}\n",
        "        model_dict.update(pretrained_dict)\n",
        "        model.load_state_dict(model_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def arlnet50(pretrained=False, **kwargs):\n",
        "    model = ARLNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model_pretrained = model_zoo.load_url(model_urls['resnet50'])\n",
        "        model_dict = model.state_dict()\n",
        "        pretrained_dict = {k: v for k, v in model_pretrained.items() if k in model_dict}\n",
        "        model_dict.update(pretrained_dict)\n",
        "        model.load_state_dict(model_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def arlnet101(pretrained=False, **kwargs):\n",
        "    model = ARLNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model_pretrained = model_zoo.load_url(model_urls['resnet101'])\n",
        "        model_dict = model.state_dict()\n",
        "        pretrained_dict = {k: v for k, v in model_pretrained.items() if k in model_dict}\n",
        "        model_dict.update(pretrained_dict)\n",
        "        model.load_state_dict(model_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def arlnet152(pretrained=False, **kwargs):\n",
        "    model = ARLNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model_pretrained = model_zoo.load_url(model_urls['resnet152'])\n",
        "        model_dict = model.state_dict()\n",
        "        pretrained_dict = {k: v for k, v in model_pretrained.items() if k in model_dict}\n",
        "        model_dict.update(pretrained_dict)\n",
        "        model.load_state_dict(model_dict)\n",
        "    return model\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model = arlnet50(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fe85803eb984b0f8a1edfd90e4c9c70",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li8XA7RmJk2V",
        "cellView": "form"
      },
      "source": [
        "#@title resnet.py || code for resnet from which ARL Model is built{form-width:\"50px\"}\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    __constants__ = ['downsample']\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "    __constants__ = ['downsample']\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
        "                 norm_layer=None):\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    # Allow for accessing forward method in a inherited class\n",
        "    forward = _forward\n",
        "\n",
        "\n",
        "def _resnet(arch, block, layers, progress, **kwargs):\n",
        "    model = ResNet(block, layers, **kwargs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet18(progress=True, **kwargs):\n",
        "    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], progress,\n",
        "                   **kwargs)\n",
        "\n",
        "\n",
        "\n",
        "def resnet34(progress=True, **kwargs):\n",
        "    return _resnet('resnet34', BasicBlock, [3, 4, 6, 3], progress,\n",
        "                   **kwargs)\n",
        "\n",
        "\n",
        "\n",
        "def resnet50(progress=True, **kwargs):\n",
        "    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], progress,\n",
        "                   **kwargs)\n",
        "\n",
        "\n",
        "\n",
        "def resnet101(progress=True, **kwargs):\n",
        "    return _resnet('resnet101', Bottleneck, [3, 4, 23, 3], progress,\n",
        "                   **kwargs)\n",
        "\n",
        "\n",
        "\n",
        "def resnet152(progress=True, **kwargs):\n",
        "    return _resnet('resnet152', Bottleneck, [3, 8, 36, 3], progress,\n",
        "                   **kwargs)\n",
        "\n",
        "\n",
        "\n",
        "def resnext50_32x4d(progress=True, **kwargs):\n",
        "    kwargs['groups'] = 32\n",
        "    kwargs['width_per_group'] = 4\n",
        "    return _resnet('resnext50_32x4d', Bottleneck, [3, 4, 6, 3], progress, **kwargs)\n",
        "\n",
        "\n",
        "\n",
        "def resnext101_32x8d(progress=True, **kwargs):\n",
        "    kwargs['groups'] = 32\n",
        "    kwargs['width_per_group'] = 8\n",
        "    return _resnet('resnext101_32x8d', Bottleneck, [3, 4, 23, 3], progress, **kwargs)\n",
        "\n",
        "\n",
        "\n",
        "def wide_resnet50_2(progress=True, **kwargs):\n",
        "    kwargs['width_per_group'] = 64 * 2\n",
        "    return _resnet('wide_resnet50_2', Bottleneck, [3, 4, 6, 3], progress, **kwargs)\n",
        "\n",
        "\n",
        "\n",
        "def wide_resnet101_2(progress=True, **kwargs):\n",
        "    kwargs['width_per_group'] = 64 * 2\n",
        "    return _resnet('wide_resnet101_2', Bottleneck, [3, 4, 23, 3], progress, **kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdwfsTzGJp6z",
        "cellView": "form"
      },
      "source": [
        "#@title Train_Mel-2.py  || Training Code { form-width: \"50px\" }\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torch.utils import data\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "RANDOM_SEED = 6666\n",
        "\n",
        "def main():\n",
        "    np.random.seed(RANDOM_SEED)\n",
        "    torch.manual_seed(RANDOM_SEED)\n",
        "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "    random.seed(RANDOM_SEED)\n",
        "\n",
        "    def train(model, dataloader, criterion, optimizer):\n",
        "        model.train()\n",
        "        losses = []\n",
        "        acc = 0.0\n",
        "        for index, (images, labels, _) in enumerate(dataloader):\n",
        "            labels = labels.to(device).unsqueeze(1).float()\n",
        "            images = images.to(device)\n",
        "            predictions = model(images)\n",
        "            loss = criterion(predictions, labels)\n",
        "            logps = F.logsigmoid(predictions)\n",
        "            ps_ = torch.exp(logps)\n",
        "            equals = torch.ge(ps_, 0.5).float() == labels\n",
        "            acc += equals.sum().item()\n",
        "            losses.append(loss.item())\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        train_loss = sum(losses) / len(losses)\n",
        "        train_acc = acc / len(dataloader.dataset)\n",
        "        print(f'\\ntrain_Accuracy: {train_acc:.5f}, train_Loss: {train_loss:.5f}')\n",
        "        return train_acc, train_loss\n",
        "\n",
        "    def validation(model, dataloader, criterion):\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            running_acc = 0.0\n",
        "            val_losses = []\n",
        "            for index, (images, labels, _) in enumerate(dataloader, start=1):\n",
        "                labels = labels.to(device).unsqueeze(1).float()\n",
        "                images = images.to(device)\n",
        "                # hogs = hogs.to(device)\n",
        "                score = []\n",
        "                for i in range(len(images[0])):\n",
        "                    ps = model(images[:,i])\n",
        "                    score.append(ps)\n",
        "                score = sum(score) / len(score)\n",
        "                logps = F.logsigmoid(score)\n",
        "                ps_ = torch.exp(logps)\n",
        "                loss = criterion(score, labels)\n",
        "                val_losses.append(loss.item())\n",
        "                equals = torch.ge(ps_, 0.5).float() == labels\n",
        "                running_acc += equals.sum().item()\n",
        "            val_loss = sum(val_losses) / len(val_losses)\n",
        "            val_acc = running_acc / len(dataloader.dataset)\n",
        "            print(f'\\nval_Accuracy: {val_acc:.5f}, val_Loss: {val_loss:.5f}')\n",
        "        return val_acc, val_loss\n",
        "\n",
        "    def save_checkpoint(epoch,acc,lr):\n",
        "        filename = os.path.join(checkpoint_dir, \"mel_arlnet50_b32_best_acc.pkl\")\n",
        "        # torch.save(model.state_dict(), filename)\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'acc': acc,\n",
        "            'lr':lr\n",
        "            }, filename)\n",
        "\n",
        "    def adjust_learning_rate():\n",
        "        nonlocal lr\n",
        "        lr = lr / lr_decay\n",
        "        return optim.SGD(model.parameters(), lr, weight_decay=weight_decay, momentum=0.9)\n",
        "\n",
        "    # set the parameters\n",
        "    data_dir = '/content/gdrive/My Drive/ISIC-2017-Org-Train-Data'\n",
        "    # Create the dataloaders\n",
        "    batch_size = 32\n",
        "    # the checkpoint dir\n",
        "    checkpoint_dir = \"/content/gdrive/My Drive/ISIC-2017-Org-Train-Data/checkpoint\"\n",
        "\n",
        "    # the learning rate para\n",
        "    lr = 1e-4\n",
        "    lr_decay = 2\n",
        "    weight_decay = 1e-4\n",
        "\n",
        "    stage = 0\n",
        "    start_epoch = 0\n",
        "    stage_epochs = [30, 30]\n",
        "    total_epochs = sum(stage_epochs)\n",
        "    writer_dir = os.path.join(checkpoint_dir, \"mel_arlnet50\")\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "\n",
        "    if not os.path.exists(writer_dir):\n",
        "        os.makedirs(writer_dir)\n",
        "\n",
        "    writer = SummaryWriter(writer_dir)\n",
        "\n",
        "    train_transforms = transforms.Compose([\n",
        "        # transforms.Resize((224, 224)),\n",
        "        transforms.RandomRotation((-10, 10)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.7079057, 0.59156483, 0.54687315],\n",
        "                             std=[0.09372108, 0.11136277, 0.12577087])\n",
        "    ])\n",
        "\n",
        "    val_transforms = argumentation_val()\n",
        "    # training dataset\n",
        "    train_dataset = ISICDataset(path=data_dir, mode=\"training\", crop=None, transform=train_transforms, task=\"mel\")\n",
        "    val_dataset = ISICDataset(path=data_dir, mode=\"validation\", crop=None, transform=val_transforms, task=\"mel\")\n",
        "    \n",
        "    # train_sampler = MySampler(train_dataset,last_index)\n",
        "    train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
        "    val_loader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=8)\n",
        "    # get the model\n",
        "    model = arlnet50(pretrained=True)\n",
        "\n",
        "    # the loss function\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = criterion.to(device)\n",
        "\n",
        "    # the optimizer\n",
        "    optimizer = optim.SGD(model.parameters(), lr, weight_decay=weight_decay, momentum=0.9)\n",
        "\n",
        "    # initialize the accuracy\n",
        "    acc = 0.0\n",
        "    flag = True\n",
        "    if flag:\n",
        "          filename = os.path.join(checkpoint_dir, \"mel_arlnet50_b32_best_acc_third.pkl\")\n",
        "          checkpoint_t = torch.load(filename)\n",
        "          model.load_state_dict(checkpoint_t['model_state_dict'])\n",
        "          optimizer.load_state_dict(checkpoint_t['optimizer_state_dict'])\n",
        "          start_epoch = checkpoint_t['epoch']\n",
        "          lr = checkpoint_t['lr']\n",
        "          acc = checkpoint_t['acc']\n",
        "    for epoch in tqdm(range(start_epoch, total_epochs)):\n",
        "        train_acc, train_loss = train(model, train_loader, criterion, optimizer)\n",
        "        val_acc, val_loss = validation(model, val_loader, criterion)\n",
        "        writer.add_scalar(\"train acc\", train_acc, epoch)\n",
        "        writer.add_scalar(\"train loss\", train_loss, epoch)\n",
        "        writer.add_scalar(\"val accuracy\", val_acc, epoch)\n",
        "        writer.add_scalar(\"val loss\", val_loss, epoch)\n",
        "\n",
        "        if val_acc > acc or val_acc == acc:\n",
        "            acc = val_acc\n",
        "            print(\"save the checkpoint, the accuracy of validation is {}\".format(acc))\n",
        "            save_checkpoint(epoch,acc,lr)\n",
        "\n",
        "        if (epoch + 1) % 50 == 0:\n",
        "            torch.save(model.state_dict(), \"/content/gdrive/My Drive/ISIC-2017-Org-Train-Data/checkpoint/mel_arlnet50/mel_arlnet50_b32_epoches_{}.pkl\".format(epoch + 1))\n",
        "\n",
        "        if (epoch + 1) in np.cumsum(stage_epochs)[:-1]:\n",
        "            stage += 1\n",
        "            optimizer = adjust_learning_rate()\n",
        "            print('Step into next stage')\n",
        "\n",
        "        if (epoch + 1) == 50:\n",
        "            torch.save(model.state_dict(), \"/content/gdrive/My Drive/ISIC-2017-Org-Train-Data/checkpoint/mel_arlnet50/mel_arlnet50_b32_epoches_{}.pkl\".format(epoch + 1))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOcm0smWLu0R",
        "cellView": "form"
      },
      "source": [
        "#@title train_sk.py {form-width : \"50px\"}\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torch.utils import data\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "RANDOM_SEED = 6666\n",
        "\n",
        "def main():\n",
        "    np.random.seed(RANDOM_SEED)\n",
        "    torch.manual_seed(RANDOM_SEED)\n",
        "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "    random.seed(RANDOM_SEED)\n",
        "\n",
        "    def train(model, dataloader, criterion, optimizer):\n",
        "        model.train()\n",
        "        losses = []\n",
        "        acc = 0.0\n",
        "        for index, (images, labels, _) in enumerate(dataloader):\n",
        "            labels = labels.to(device).unsqueeze(1).float()\n",
        "            images = images.to(device)\n",
        "            predictions = model(images)\n",
        "            loss = criterion(predictions, labels)\n",
        "            logps = F.logsigmoid(predictions)\n",
        "            ps_ = torch.exp(logps)\n",
        "            equals = torch.ge(ps_, 0.5).float() == labels\n",
        "            acc += equals.sum().item()\n",
        "            losses.append(loss.item())\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        train_loss = sum(losses) / len(losses)\n",
        "        train_acc = acc / len(dataloader.dataset)\n",
        "        print(f'\\ntrain_Accuracy: {train_acc:.5f}, train_Loss: {train_loss:.5f}')\n",
        "        return train_acc, train_loss\n",
        "\n",
        "    def validation(model, dataloader, criterion):\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            running_acc = 0.0\n",
        "            val_losses = []\n",
        "            for index, (images, labels, _) in enumerate(dataloader, start=1):\n",
        "                labels = labels.to(device).unsqueeze(1).float()\n",
        "                images = images.to(device)\n",
        "                # hogs = hogs.to(device)\n",
        "                score = []\n",
        "                for i in range(len(images[0])):\n",
        "                    ps = model(images[:,i])\n",
        "                    score.append(ps)\n",
        "                score = sum(score) / len(score)\n",
        "                logps = F.logsigmoid(score)\n",
        "                ps_ = torch.exp(logps)\n",
        "                loss = criterion(score, labels)\n",
        "                val_losses.append(loss.item())\n",
        "                equals = torch.ge(ps_, 0.5).float() == labels\n",
        "                running_acc += equals.sum().item()\n",
        "            val_loss = sum(val_losses) / len(val_losses)\n",
        "            val_acc = running_acc / len(dataloader.dataset)\n",
        "            print(f'\\nval_Accuracy: {val_acc:.5f}, val_Loss: {val_loss:.5f}')\n",
        "        return val_acc, val_loss\n",
        "\n",
        "    def save_checkpoint():\n",
        "        filename = os.path.join(checkpoint_dir, \"sk_arlnet50_b32_best_acc.pkl\")\n",
        "        # torch.save(model.state_dict(), filename)\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict()\n",
        "            }, filename)\n",
        "\n",
        "    def adjust_learning_rate():\n",
        "        nonlocal lr\n",
        "        lr = lr / lr_decay\n",
        "        return optim.SGD(model.parameters(), lr, weight_decay=weight_decay, momentum=0.9)\n",
        "\n",
        "    # set the parameters\n",
        "    data_dir = '/content/gdrive/My Drive/ISIC-2017-Org-Train-Data'\n",
        "    # Create the dataloaders\n",
        "    batch_size = 32\n",
        "    # the checkpoint dir\n",
        "    checkpoint_dir = \"/content/gdrive/My Drive/ISIC-2017-Org-Train-Data/checkpoint2\"\n",
        "\n",
        "    # the learning rate para\n",
        "    lr = 1e-4\n",
        "    lr_decay = 2\n",
        "    weight_decay = 1e-4\n",
        "\n",
        "    stage = 0\n",
        "    start_epoch = 0\n",
        "    stage_epochs = [30, 30, 30, 10]\n",
        "    total_epochs = sum(stage_epochs)\n",
        "    writer_dir = os.path.join(checkpoint_dir, \"sk_arlnet50\")\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "\n",
        "    if not os.path.exists(writer_dir):\n",
        "        os.makedirs(writer_dir)\n",
        "\n",
        "    writer = SummaryWriter(writer_dir)\n",
        "\n",
        "    train_transforms = transforms.Compose([\n",
        "        # transforms.Resize((224, 224)),\n",
        "        transforms.RandomRotation((-10, 10)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.7079057, 0.59156483, 0.54687315],\n",
        "                             std=[0.09372108, 0.11136277, 0.12577087])\n",
        "    ])\n",
        "\n",
        "    val_transforms = argumentation_val()\n",
        "    # training dataset\n",
        "    train_dataset = ISICDataset(path=data_dir, mode=\"training\", crop=None, transform=train_transforms, task=\"sk\")\n",
        "    val_dataset = ISICDataset(path=data_dir, mode=\"validation\", crop=None, transform=val_transforms, task=\"sk\")\n",
        "\n",
        "    train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
        "    val_loader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=8)\n",
        "    # get the model\n",
        "    model = arlnet50(pretrained=True)\n",
        "\n",
        "    # the loss function\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = criterion.to(device)\n",
        "\n",
        "    # the optimizer\n",
        "    optimizer = optim.SGD(model.parameters(), lr, weight_decay=weight_decay, momentum=0.9)\n",
        "\n",
        "    # initialize the accuracy\n",
        "    acc = 0.0\n",
        "    for epoch in tqdm(range(start_epoch, total_epochs)):\n",
        "\n",
        "        train_acc, train_loss = train(model, train_loader, criterion, optimizer)\n",
        "        val_acc, val_loss = validation(model, val_loader, criterion)\n",
        "        writer.add_scalar(\"train acc\", train_acc, epoch)\n",
        "        writer.add_scalar(\"train loss\", train_loss, epoch)\n",
        "        writer.add_scalar(\"val accuracy\", val_acc, epoch)\n",
        "        writer.add_scalar(\"val loss\", val_loss, epoch)\n",
        "\n",
        "        if val_acc > acc or val_acc == acc:\n",
        "            acc = val_acc\n",
        "            print(\"save the checkpoint, the accuracy of validation is {}\".format(acc))\n",
        "            save_checkpoint()\n",
        "\n",
        "        if (epoch + 1) % 50 == 0:\n",
        "            torch.save(model.state_dict(), \"/content/gdrive/My Drive/ISIC-2017-Org-Train-Data/checkpoint2/sk_arlnet50/sk_arlnet50_b32_epoches_{}.pkl\".format(epoch + 1))\n",
        "\n",
        "        if (epoch + 1) in np.cumsum(stage_epochs)[:-1]:\n",
        "            stage += 1\n",
        "            optimizer = adjust_learning_rate()\n",
        "            print('Step into next stage')\n",
        "\n",
        "        if (epoch + 1) == 50:\n",
        "            torch.save(model.state_dict(), \"/content/gdrive/My Drive/ISIC-2017-Org-Train-Data/checkpoint2/sk_arlnet50/sk_arlnet50_b32_epoches_{}.pkl\".format(epoch + 1))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEIDsRmLJv-H"
      },
      "source": [
        "#@title predict_mel_2017.py || Code for Testing and to display metrics { form-width: \"50px\" }\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "RANDOM_SEED = 6666\n",
        "\n",
        "\n",
        "def main():\n",
        "    np.random.seed(RANDOM_SEED)\n",
        "    torch.manual_seed(RANDOM_SEED)\n",
        "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "    random.seed(RANDOM_SEED)\n",
        "\n",
        "    # set the parameters\n",
        "    checkpoint_dir = base_path + \"rand/mel_arlnet50_b32_best_acc.pkl\"\n",
        "    result_dir = base_path + \"result\"\n",
        "    data_dir = base_path\n",
        "    # Create the dataloaders\n",
        "    batch_size = 1\n",
        "\n",
        "    y = []\n",
        "    y_score = []\n",
        "\n",
        "    if not os.path.exists(result_dir):\n",
        "        os.makedirs(result_dir)\n",
        "\n",
        "    def imshow(y_pre, y_score):\n",
        "        fpr, tpr, thresholds = metrics.roc_curve(y_pre, y_score)\n",
        "        auc = metrics.auc(fpr, tpr)\n",
        "        print(auc)\n",
        "\n",
        "        plt.plot(fpr, tpr, c='r', lw=2, alpha=0.7, label=u'AUC=%.3f' % auc)\n",
        "        plt.plot((0, 1), (0, 1), c='#808080', lw=1, ls='--', alpha=0.7)\n",
        "        plt.xlim((-0.01, 1.02))\n",
        "        plt.ylim((-0.01, 1.02))\n",
        "        plt.xticks(np.arange(0, 1.1, 0.1))\n",
        "        plt.yticks(np.arange(0, 1.1, 0.1))\n",
        "        plt.xlabel('False Positive Rate', fontsize=13)\n",
        "        plt.ylabel('True Positive Rate', fontsize=13)\n",
        "        plt.grid(b=True, ls=':')\n",
        "        plt.legend(loc='lower right', fancybox=True, framealpha=0.8, fontsize=12)\n",
        "        plt.title(u'ROC and AUC', fontsize=17)\n",
        "        plt.savefig(\"/content/gdrive/My Drive/ISIC-2017-Org-Train-Data/ISIC-2017_Training_Data/2017_mel_arlnet50_e100_b32_fourth.png\")\n",
        "\n",
        "\n",
        "    def load_checkpoint(checkpoint_path):\n",
        "        model = arlnet50(pretrained=True)\n",
        "        checkpoint_t = torch.load(checkpoint_path, map_location='cuda')\n",
        "        model.load_state_dict(checkpoint_t['model_state_dict'])  # your checkpoint's key may differ (e.g.'state_dict')\n",
        "        model.eval()\n",
        "        return model\n",
        "\n",
        "    def predict(model, dataloader):\n",
        "        mel_tn = 0\n",
        "        mel_fp = 0\n",
        "        mel_tp = 0\n",
        "        mel_fn = 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for ii, (images, labels, _) in tqdm(enumerate(dataloader, start=1)):\n",
        "                images = images.to(device)\n",
        "                scores = []\n",
        "              \n",
        "                for i in range(len(images[0])):\n",
        "                    pred = model(images[:, i])\n",
        "                    scores.append(pred)\n",
        "                scores = sum(scores) / len(scores)\n",
        "                logps = F.logsigmoid(scores)\n",
        "                score = torch.exp(logps)\n",
        "                pre = torch.ge(score, 0.5).float()\n",
        "                if int(pre) == 0 and int(labels) == 0:\n",
        "                    mel_tn += 1\n",
        "                elif int(pre) == 1 and int(labels) == 0:\n",
        "                    mel_fp += 1\n",
        "                elif int(pre) == 1 and int(labels) == 1:\n",
        "                    mel_tp += 1\n",
        "                elif int(pre) == 0 and int(labels) == 1:\n",
        "                    mel_fn += 1\n",
        "                score = score.cpu().numpy().tolist()[0]\n",
        "                label = labels.cpu().numpy().tolist()[0]\n",
        "                y.append(label)\n",
        "                y_score.append(score)\n",
        "        return mel_tp, mel_tn, mel_fp, mel_fn\n",
        "\n",
        "    val_transforms = argumentation_val()\n",
        "    # Validation dataset\n",
        "    val_dataset = ISICDataset(path=data_dir, mode=\"testing\", crop=None, transform=val_transforms, task=\"mel\")\n",
        "    val_loader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    model = load_checkpoint(checkpoint_path=checkpoint_dir)\n",
        "\n",
        "    model.cuda()\n",
        "    mel_tp, mel_tn, mel_fp, mel_fn = predict(model, val_loader)\n",
        "\n",
        "    mel_acc = (mel_tp + mel_tn) / (mel_tn + mel_fp + mel_tp + mel_fn)\n",
        "    mel_sen = mel_tp / (mel_tp + mel_fn)\n",
        "    mel_spe = mel_tn / (mel_tn + mel_fp)\n",
        "\n",
        "    y_score = np.array(y_score)\n",
        "    mel_auc = metrics.roc_auc_score(y, y_score)\n",
        "\n",
        "    imshow(y, y_score)\n",
        "\n",
        "    print('mel_Accuracy:', mel_acc)\n",
        "    print('mel_Sensitive:', mel_sen)\n",
        "    print('mel_Specificity:', mel_spe)\n",
        "    print('mel_AUC:', mel_auc)\n",
        "    with open('/content/gdrive/My Drive/ISIC-2017-Org-Train-Data/result/result_fourth.txt', 'a') as f:\n",
        "        f.write('\\n2017_mel_arlnet50_e100_b32: ' + json.dumps(\n",
        "            {'mel_Accuracy': mel_acc, 'mel_Sensitive': mel_sen, 'mel_Specificity': mel_spe, 'mel_AUC': mel_auc}))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPHPdosxwLa6",
        "cellView": "form"
      },
      "source": [
        "#@title predict_sk_2017.py || Code for Testing and to display metrics { form-width: \"50px\" }\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "RANDOM_SEED = 6666\n",
        "\n",
        "\n",
        "def main():\n",
        "    np.random.seed(RANDOM_SEED)\n",
        "    torch.manual_seed(RANDOM_SEED)\n",
        "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "    random.seed(RANDOM_SEED)\n",
        "\n",
        "    # set the parameters\n",
        "    checkpoint_dir = base_path + \"rand/sk_arlnet50_b32_best_acc.pkl\"\n",
        "    result_dir = base_path + \"result2\"\n",
        "    data_dir = base_path\n",
        "    # Create the dataloaders\n",
        "    batch_size = 1\n",
        "\n",
        "    y = []\n",
        "    y_score = []\n",
        "\n",
        "    if not os.path.exists(result_dir):\n",
        "        os.makedirs(result_dir)\n",
        "\n",
        "    def imshow(y_pre, y_score):\n",
        "        fpr, tpr, thresholds = metrics.roc_curve(y_pre, y_score)\n",
        "        auc = metrics.auc(fpr, tpr)\n",
        "        print(auc)\n",
        "\n",
        "        plt.plot(fpr, tpr, c='r', lw=2, alpha=0.7, label=u'AUC=%.3f' % auc)\n",
        "        plt.plot((0, 1), (0, 1), c='#808080', lw=1, ls='--', alpha=0.7)\n",
        "        plt.xlim((-0.01, 1.02))\n",
        "        plt.ylim((-0.01, 1.02))\n",
        "        plt.xticks(np.arange(0, 1.1, 0.1))\n",
        "        plt.yticks(np.arange(0, 1.1, 0.1))\n",
        "        plt.xlabel('False Positive Rate', fontsize=13)\n",
        "        plt.ylabel('True Positive Rate', fontsize=13)\n",
        "        plt.grid(b=True, ls=':')\n",
        "        plt.legend(loc='lower right', fancybox=True, framealpha=0.8, fontsize=12)\n",
        "        plt.title(u'ROC and AUC', fontsize=17)\n",
        "        plt.savefig(\"/content/gdrive/My Drive/ISIC-2017-Org-Train-Data/2017_sk_arlnet50_e100_b32.png\")\n",
        "\n",
        "\n",
        "    def load_checkpoint(checkpoint_path):\n",
        "\n",
        "        model = arlnet50(pretrained=True)\n",
        "        # checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
        "        checkpoint_t = torch.load(checkpoint_path, map_location='cuda')\n",
        "        model.load_state_dict(checkpoint_t['model_state_dict'])  # your checkpoint's key may differ (e.g.'state_dict')\n",
        "        model.eval()\n",
        "        return model\n",
        "\n",
        "    def predict(model, dataloader):\n",
        "        mel_tn = 0\n",
        "        mel_fp = 0\n",
        "        mel_tp = 0\n",
        "        mel_fn = 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for ii, (images, labels, _) in tqdm(enumerate(dataloader, start=1)):\n",
        "                images = images.to(device)\n",
        "                scores = []\n",
        "\n",
        "                for i in range(len(images[0])):\n",
        "                    pred = model(images[:, i])\n",
        "                    scores.append(pred)\n",
        "                scores = sum(scores) / len(scores)\n",
        "                logps = F.logsigmoid(scores)\n",
        "                score = torch.exp(logps)\n",
        "                pre = torch.ge(score, 0.5).float()\n",
        "                if int(pre) == 0 and int(labels) == 0:\n",
        "                    mel_tn += 1\n",
        "                elif int(pre) == 1 and int(labels) == 0:\n",
        "                    mel_fp += 1\n",
        "                elif int(pre) == 1 and int(labels) == 1:\n",
        "                    mel_tp += 1\n",
        "                elif int(pre) == 0 and int(labels) == 1:\n",
        "                    mel_fn += 1\n",
        "                score = score.cpu().numpy().tolist()[0]\n",
        "                label = labels.cpu().numpy().tolist()[0]\n",
        "                y.append(label)\n",
        "                y_score.append(score)\n",
        "        return mel_tp, mel_tn, mel_fp, mel_fn\n",
        "\n",
        "    val_transforms = argumentation_val()\n",
        "    # Validation dataset\n",
        "    val_dataset = ISICDataset(path=data_dir, mode=\"testing\", crop=None, transform=val_transforms, task=\"sk\")\n",
        "    val_loader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    model = load_checkpoint(checkpoint_path=checkpoint_dir)\n",
        "\n",
        "    model.cuda()\n",
        "    mel_tp, mel_tn, mel_fp, mel_fn = predict(model, val_loader)\n",
        "\n",
        "    mel_acc = (mel_tp + mel_tn) / (mel_tn + mel_fp + mel_tp + mel_fn)\n",
        "    mel_sen = mel_tp / (mel_tp + mel_fn)\n",
        "    mel_spe = mel_tn / (mel_tn + mel_fp)\n",
        "\n",
        "    y_score = np.array(y_score)\n",
        "    mel_auc = metrics.roc_auc_score(y, y_score)\n",
        "\n",
        "    imshow(y, y_score)\n",
        "\n",
        "    print('sk_Accuracy:', mel_acc)\n",
        "    print('sk_Sensitive:', mel_sen)\n",
        "    print('sk_Specificity:', mel_spe)\n",
        "    print('sk_AUC:', mel_auc)\n",
        "    with open('/content/gdrive/My Drive/ISIC-2017-Org-Train-Data/result2/result.txt', 'a') as f:\n",
        "        f.write('\\n2017_sk_arlnet50_e100_b32: ' + json.dumps(\n",
        "            {'sk_Accuracy': mel_acc, 'sk_Sensitive': mel_sen, 'sk_Specificity': mel_spe, 'sk_AUC': mel_auc}))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtG6j8MnX2oI"
      },
      "source": [
        "import torch\n",
        "checkpoint_dir = \"/content/gdrive/MyDrive/ISIC-2017-Org-Train-Data/rand/mel_arlnet50_b32_best_acc.pkl\"\n",
        "checkpoint_t = torch.load(checkpoint_dir, map_location='cuda')\n",
        "def save_checkpoint():\n",
        "  filename = \"/content/gdrive/MyDrive/ISIC-2017-Org-Train-Data/checkpoint2/mel_model_weights.pkl\"\n",
        "  torch.save(checkpoint_t['model_state_dict'], filename)\n",
        "save_checkpoint()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}